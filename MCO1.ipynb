{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCO1 - Labor Force Survey 2016\n",
    "\n",
    "**Members**\n",
    "* Dy, Harmony Claire\n",
    "* Hernandez, Christa Ysabel\n",
    "* Sanchez, Matthew Heinz\n",
    "* Uy, Justine Nicole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction to the problem/task and dataset\n",
    "Each group should select one real-world dataset from the list of datasets provided for the\n",
    "project. Each dataset is accompanied with a description file, which also contains detailed\n",
    "description of each feature.\n",
    "The target task (i.e., classification or regression) should be properly stated as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[brief description of the dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Provide a description of the collection process executed to build the dataset. Discuss the implications of the data collection method on the generated conclusions and insights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"PHL-PSA-LFS-2016-Q2-PUF/LFS PUF April 2016.CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Describe the structure of the dataset file.\n",
    "\n",
    "o What does each row and column represent?\n",
    "\n",
    "o How many instances are there in the dataset?\n",
    "\n",
    "o How many features are there in the dataset?\n",
    "\n",
    "o If the dataset is composed of different files that you will combine in the succeeding\n",
    "steps, describe the structure and the contents of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Discuss the features in each dataset file. What does each feature represent? All features,\n",
    "even those which are not used for the study, should be described to the reader. The\n",
    "purpose of each feature in the dataset should be clear to the reader of the notebook\n",
    "without having to go through an external link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. List of requirements\n",
    "List all the Python libraries and modules that you used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Data preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Exploratory data analysis\n",
    "Perform exploratory data analysis comprehensively to gain a good understanding of your dataset.\n",
    "In this section of the notebook, you must present relevant numerical summaries and\n",
    "visualizations. Make sure that each code is accompanied by a brief explanation. The whole\n",
    "process should be supported with verbose textual descriptions of your procedures and findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Initial model training\n",
    "Use machine learning models to accomplish your chosen task (i.e., classification or regression)\n",
    "for the dataset. In this section of the notebook, please take note of the following:\n",
    "* The project should train and evaluate at least 3 different kinds of machine learning\n",
    "models. The models should not be multiple variations of the same model, e.g., three\n",
    "neural network models with different number of neurons.\n",
    "* Each model should be appropriate in accomplishing the chosen task for the dataset.\n",
    "There should be a clear and correct justification on the use of each machine learning\n",
    "model.\n",
    "* Make sure that the values of the hyperparameters of each model are mentioned. At the\n",
    "minimum, the optimizer, the learning rate, and the learning rate schedule should be\n",
    "discussed per model.\n",
    "* The report should show that the models are not overfitting nor underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7. Error analysis\n",
    "Perform error analysis on the output of all models used in the project. In this section of the\n",
    "notebook, you should:\n",
    "* Report and properly interpret the initial performance of all models using appropriate\n",
    "evaluation metrics.\n",
    "* Identify difficult classes and/or instances. For classification tasks, these are classes\n",
    "and/or instances that are difficult to classify. Hint: You may use confusion matrix for\n",
    "this. For regression tasks, these are instances that produces high error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8. Improving model performance\n",
    "Perform grid search or random search to tune the hyperparameters of each model. You should\n",
    "also tune each model to reduce the error in difficult classes and/or instances. In this section of\n",
    "the notebook, please take note of the following:\n",
    "* Make sure to elaborately explain the method of hyperparameter tuning.\n",
    "* Explicitly mention the different hyperparameters and their range of values. Show the\n",
    "corresponding performance of each configuration.\n",
    "* Report the performance of all models using appropriate evaluation metrics and\n",
    "visualizations.\n",
    "* Properly interpret the result based on relevant evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9. Model performance summary\n",
    "Present a summary of all model configurations. In this section of the notebook, do the\n",
    "following:\n",
    "* Discuss each algorithm and the best set of values for its hyperparameters. Identify the\n",
    "best model configuration and discuss its advantage over other configurations.\n",
    "* Discuss how tuning each model helped in reducing its error in difficult classes and/or\n",
    "instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10. Insights and conclusions\n",
    "Clearly state your insights and conclusions from training a model on the data. Why did some\n",
    "models produce better results? Summarize your conclusions to explain the performance of the\n",
    "models. Discuss recommendations to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11. References\n",
    "Cite relevant references that you used in your project. All references must be cited, including:\n",
    "* Scholarly Articles – Cite in APA format and put a description of how you used it for your\n",
    "work.\n",
    "* Online references, blogs, articles that helped you come up with your project – Put the\n",
    "website, blog, or article title, link, and how you incorporated it into your work.\n",
    "* Artificial Intelligence (AI) Tools – Put the model used (e.g., ChatGPT, Gemini), the complete\n",
    "transcript of your conversations with the model (including your prompts and its\n",
    "responses), and a description of how you used it for your work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
